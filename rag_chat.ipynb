{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaK62oX3NhRf"
      },
      "source": [
        "# 基于langchain创建自己专属的对话大模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. 领域精准问答\n",
        "2. 数据更新频繁\n",
        "3. 生成内容可解释可追溯\n",
        "4. 数据隐私保护"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-173FmLdNhRj"
      },
      "source": [
        "通过这个例子，我们将基于`LangChain`, `OpenAI(LLM)`,  `vector DB`构建一个属于自己的LLM模型。\n",
        "\n",
        "主要使用的技术————***Retrieval Augmented Generation (RAG)***\n",
        "\n",
        "首先确保自己拥有一个 `OpenAI API key` (也并非必须)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzzHZ2sLNhRk"
      },
      "source": [
        "### 准备环境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAivifIqNhRk",
        "outputId": "53e3378c-79df-43e8-c92a-c0dce00dcaa0"
      },
      "outputs": [],
      "source": [
        "! pip install -qU \\\n",
        "    langchain==0.0.316 \\\n",
        "    openai==0.28.1  \\\n",
        "    tiktoken==0.5.1  \\\n",
        "    cohere \\\n",
        "    chromadb==0.4.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Eg0ay3TNhRm"
      },
      "source": [
        "### 创建一个对话模型(no RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd3OUQIWNhRm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
        "os.environ[\"base_url\"] = \"...\"\n",
        "\n",
        "chat = ChatOpenAI(\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    openai_api_base=os.environ[\"base_url\"],\n",
        "    model='gpt-3.5-turbo'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAxQlUl1Cwom"
      },
      "source": [
        "OpenAI Python 的例子\n",
        "```python\n",
        "[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
        "    {\"role\": \"user\", \"content\": \"Orange.\"},\n",
        "]\n",
        "```\n",
        "https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models\n",
        "\n",
        "\n",
        "但是langchain 需要使用以下的格式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jbPKtHYsNhRn"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain.schema import (\n",
        "    SystemMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage\n",
        ")\n",
        "\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"Knock knock.\"),\n",
        "    AIMessage(content=\"Who's there?\"),\n",
        "    HumanMessage(content=\"Orange\"),\n",
        "    \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11iDGkWPNhRn",
        "outputId": "e3698bd8-b14b-4abf-957f-041c0abd7f7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Orange who?')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = chat(messages)\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7db28OOMjig"
      },
      "source": [
        "因为 `res`也是`AIMessage`属性，所以我们可以直接进行添加，即可实现下一次的响应"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85dW12laNLmO",
        "outputId": "7e431e35-7673-41d3-8ac7-a4b352c1b1be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Orange you glad I'm here to assist you?\n"
          ]
        }
      ],
      "source": [
        "messages.append(res)\n",
        "res = chat(messages)\n",
        "\n",
        "print(res.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YtYH-1oNhRo",
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "#### 处理LLM存在的缺陷\n",
        "1. 容易出现幻觉\n",
        "2. 信息滞后\n",
        "3. 专业领域深度知识匮乏\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PZxdF06NhRp"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"你是一个专业的知识助手。\"),\n",
        "    HumanMessage(content=\"你知道baichuan2模型吗？\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw-ylWZMQW5z",
        "outputId": "f4ff154a-c8af-457c-a2db-fa310b92ccc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "是的，我了解baichuan2模型。baichuan2是一种基于深度学习的图像分割模型，主要用于图像语义分割任务。它采用了编码-解码的架构，通过卷积神经网络提取图像特征，并将特征映射到与输入图像大小相同的分割结果。baichuan2模型在许多图像分割比赛和任务中取得了很好的性能，并被广泛应用于医学图像分割、自动驾驶、图像编辑等领域。\n"
          ]
        }
      ],
      "source": [
        "res = chat(messages)\n",
        "print(res.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXir07e9yKNW"
      },
      "source": [
        "chatgpt AI无法满足我们在某些特定领域的专业需求，我们可以通过知识注入的方式，利用prompt来解决这种问题："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MTJRA2nQW_E"
      },
      "outputs": [],
      "source": [
        "\n",
        "baichuan2_information = [\n",
        "    \"Baichuan 2是一个大规模多语言语言模型，它专注于训练在多种语言中表现优异的模型，包括不仅限于英文。这使得Baichuan 2在处理各种语言的任务时能够取得显著的性能提升。\",\n",
        "    \"Baichuan 2是从头开始训练的，使用了包括了2.6万亿个标记的庞大训练数据集。相对于以往的模型，Baichuan 2提供了更丰富的数据资源，从而能够更好地支持多语言的开发和应用。\",\n",
        "    \"Baichuan 2不仅在通用任务上表现出色，还在特定领域（如医学和法律）的任务中展现了卓越的性能。这为特定领域的应用提供了强有力的支持。\"\n",
        "]\n",
        "\n",
        "source_knowledge = \"\\n\".join(baichuan2_information)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHKTgq08NhRp",
        "outputId": "d6333937-c854-4b1e-8a12-2bc1d1a33301"
      },
      "outputs": [],
      "source": [
        "print(source_knowledge)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdgyyDx2yx8M"
      },
      "outputs": [],
      "source": [
        "query = \"你知道baichuan2模型吗？\"\n",
        "\n",
        "prompt_template = f\"\"\"基于以下内容回答问题：\n",
        "\n",
        "内容:\n",
        "{source_knowledge}\n",
        "\n",
        "Query: {query}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwSPm_3qzWB7"
      },
      "outputs": [],
      "source": [
        "prompt = HumanMessage(\n",
        "    content=prompt_template\n",
        ")\n",
        "messages.append(prompt)\n",
        "\n",
        "res = chat(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P861bTreziWz",
        "outputId": "62aaf1ba-aebe-4576-c5cc-7203f677d205"
      },
      "outputs": [],
      "source": [
        "print(res.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Npmwyy808i6"
      },
      "source": [
        "当我们注入一些专业的知识后，模型就能够很好的回答相关问题。\n",
        "如果每一个问题都去用相关的外部知识进行增强拼接的话，那么回答的准确性就大大增加？？？？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXfTkYm01oWp"
      },
      "source": [
        "### 创建一个RAG对话模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8TTksfT2K3r"
      },
      "source": [
        "#### 1. 加载数据 （以baichuan2论文为例）\n",
        "\n",
        "   https://arxiv.org/pdf/2309.10305v2.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIVOnz1TxkZ4",
        "outputId": "aeeee9d2-98e0-42b1-b8f5-8ef430eb7f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
            "Collecting pypdf\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/c5/16/a5619a9d9bd4601126b95a9026eccfe4ebb74d725b7fdf624680e5a1f502/pypdf-5.6.1-py3-none-any.whl (304 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from pypdf) (4.14.0)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-5.6.1\n"
          ]
        }
      ],
      "source": [
        "! pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD-UF8z06txb"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"https://arxiv.org/pdf/2309.10305.pdf\")\n",
        "pages = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KsCy_vTs68I-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='Baichuan 2: Open Large-scale Language Models\\nAiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan\\nDian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai\\nGuosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji\\nJian Xie, Juntao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma\\nMang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun\\nTao Zhang, Tianpeng Li, Tianyu Li, Wei Cheng, Weipeng Chen, Xiangrong Zeng\\nXiaochuan Wang, Xiaoxi Chen, Xin Men, Xin Yu, Xuehai Pan, Yanjun Shen, Yaodong Yang\\nYiding Wang, Yiyu Li, Youxin Jiang, Yuchen Gao, Yupeng Zhang, Zenan Zhou, Zhiying Wu\\nBaichuan Inc.\\nAbstract\\nLarge language models (LLMs) have\\ndemonstrated remarkable performance on\\na variety of natural language tasks based\\non just a few examples of natural language\\ninstructions, reducing the need for extensive\\nfeature engineering. However, most powerful\\nLLMs are closed-source or limited in their\\ncapability for languages other than English. In\\nthis technical report, we present Baichuan 2,\\na series of large-scale multilingual language\\nmodels containing 7 billion and 13 billion\\nparameters, trained from scratch, on 2.6 trillion\\ntokens. Baichuan 2 matches or outperforms\\nother open-source models of similar size on\\npublic benchmarks like MMLU, CMMLU,\\nGSM8K, and HumanEval. Furthermore,\\nBaichuan 2 excels in vertical domains such\\nas medicine and law. We will release all\\npre-training model checkpoints to benefit the\\nresearch community in better understanding\\nthe training dynamics of Baichuan 2.\\n1 Introduction\\nThe field of large language models has witnessed\\npromising and remarkable progress in recent years.\\nThe size of language models has grown from\\nmillions of parameters, such as ELMo (Peters\\net al., 2018), GPT-1 (Radford et al., 2018), to\\nbillions or even trillions of parameters such as GPT-\\n3 (Brown et al., 2020), PaLM (Chowdhery et al.,\\n2022; Anil et al., 2023) and Switch Transformers\\n(Fedus et al., 2022). This increase in scale has\\nled to significant improvements in the capabilities\\nof language models, enabling more human-like\\nAuthors are listed alphabetically, correspondent:\\ndaniel@baichuan-inc.com.\\nJiaming Ji, Borong Zhang, Xuehai Pan, Mickel Liu,\\nJuntao Dai, Ruiyang Sun, Yaodong Yang affiliated with Peking\\nUniversity.\\nfluency and the ability to perform a diverse range\\nof natural language tasks. With the introduction of\\nChatGPT (OpenAI, 2022) from OpenAI, the power\\nof these models to generate human-like text has\\ncaptured widespread public attention. ChatGPT\\ndemonstrates strong language proficiency across\\na variety of domains, from conversing casually to\\nexplaining complex concepts. This breakthrough\\nhighlights the potential for large language models\\nto automate tasks involving natural language\\ngeneration and comprehension.\\nWhile there have been exciting breakthroughs\\nand applications of LLMs, most leading LLMs like\\nGPT-4 (OpenAI, 2023), PaLM-2 (Anil et al., 2023),\\nand Claude (Claude, 2023) remain closed-sourced.\\nDevelopers and researchers have limited access to\\nthe full model parameters, making it difficult for\\nthe community to deeply study or fine-tune these\\nsystems. More openness and transparency around\\nLLMs could accelerate research and responsible\\ndevelopment within this rapidly advancing field.\\nLLaMA (Touvron et al., 2023a), a series of large\\nlanguage models developed by Meta containing up\\nto 65 billion parameters, has significantly benefited\\nthe LLM research community by being fully open-\\nsourced. The open nature of LLaMA, along with\\nother open-source LLMs such as OPT (Zhang\\net al., 2022), Bloom (Scao et al., 2022), MPT\\n(MosaicML, 2023) and Falcon (Penedo et al.,\\n2023), enables researchers to freely access the\\nmodels for examination, experimentation, and\\nfurther development. This transparency and access\\ndistinguishes LLaMA from other proprietary\\nLLMs. By providing full access, the open-source\\nLLMs have accelerated research and advances in', metadata={'source': 'C:\\\\Users\\\\kalin\\\\AppData\\\\Local\\\\Temp\\\\tmpchwtntxm\\\\tmp.pdf', 'page': 0})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pages[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZN6yzwi7J61"
      },
      "source": [
        "#### 2. 知识切片 将文档分割成均匀的块。每个块是一段原始文本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wt3G5-ph7gho"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap = 50,\n",
        ")\n",
        "\n",
        "docs = text_splitter.split_documents(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCXqYY4D7gkp",
        "outputId": "d92b8a52-fe1e-4480-db30-1aa2f15b6716"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "216"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgABYtKp8_Ke"
      },
      "source": [
        "#### 3. 利用embedding模型对每个文本片段进行向量化，并储存到向量数据库中"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "AmI_-A1-ziZN"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "\n",
        "embed_model = OpenAIEmbeddings(\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    openai_api_base=os.environ[\"base_url\"]\n",
        ")\n",
        "vectorstore = Chroma.from_documents(documents=docs, embedding=embed_model , collection_name=\"openai_embed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-fgbDgQC77h"
      },
      "source": [
        "#### 4. 通过向量相似度检索和问题最相关的K个文档。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zuoRfbU_Du3S"
      },
      "outputs": [],
      "source": [
        "query = \"How large is the baichuan2 vocabulary?\"\n",
        "result = vectorstore.similarity_search(query ,k = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dliY5xHaC2NN",
        "outputId": "40191eee-e17e-4283-e63b-f5ff2088bdf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='capabilities in other languages. This hinders the\\ndevelopment and application of LLMs in specific\\nlanguages, such as Chinese.\\nIn this technical report, we introduce Baichuan\\n2, a series of large-scale multilingual language\\nmodels. Baichuan 2 has two separate models,\\nBaichuan 2-7B with 7 billion parameters and\\nBaichuan 2-13B with 13 billion parameters. Both\\nmodels were trained on 2.6 trillion tokens, which\\nto our knowledge is the largest to date, more than', metadata={'page': 1, 'source': 'C:\\\\Users\\\\kalin\\\\AppData\\\\Local\\\\Temp\\\\tmpchwtntxm\\\\tmp.pdf'}),\n",
              " Document(page_content='Baichuan 2: Open Large-scale Language Models\\nAiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan\\nDian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai\\nGuosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji\\nJian Xie, Juntao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma\\nMang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun', metadata={'page': 0, 'source': 'C:\\\\Users\\\\kalin\\\\AppData\\\\Local\\\\Temp\\\\tmpchwtntxm\\\\tmp.pdf'})]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymUjel7-E-t1"
      },
      "source": [
        "#### 5. 原始`query`与检索得到的文本组合起来输入到语言模型，得到最终的回答"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9wBIBDnIC2P8"
      },
      "outputs": [],
      "source": [
        "def augment_prompt(query: str):\n",
        "  # 获取top3的文本片段\n",
        "  results = vectorstore.similarity_search(query, k=3)\n",
        "  source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
        "  # 构建prompt\n",
        "  augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
        "\n",
        "  contexts:\n",
        "  {source_knowledge}\n",
        "\n",
        "  query: \n",
        "  {query}\n",
        "  \"\"\"\n",
        "  return augmented_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JHTutK09GRSx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using the contexts below, answer the query.\n",
            "\n",
            "  contexts:\n",
            "  capabilities in other languages. This hinders the\n",
            "development and application of LLMs in specific\n",
            "languages, such as Chinese.\n",
            "In this technical report, we introduce Baichuan\n",
            "2, a series of large-scale multilingual language\n",
            "models. Baichuan 2 has two separate models,\n",
            "Baichuan 2-7B with 7 billion parameters and\n",
            "Baichuan 2-13B with 13 billion parameters. Both\n",
            "models were trained on 2.6 trillion tokens, which\n",
            "to our knowledge is the largest to date, more than\n",
            "Baichuan 2: Open Large-scale Language Models\n",
            "Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan\n",
            "Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai\n",
            "Guosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji\n",
            "Jian Xie, Juntao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma\n",
            "Mang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun\n",
            "Baichuan 1 64,000 0.570\n",
            "Baichuan 2 125,696 0.498\n",
            "Table 2: The vocab size and text compression rate of\n",
            "Baichuan 2’s tokenizer compared with other models.\n",
            "The lower the better.\n",
            "We use byte-pair encoding (BPE) (Shibata et al.,\n",
            "1999) from SentencePiece (Kudo and Richardson,\n",
            "\n",
            "  query: \n",
            "  How large is the baichuan2 vocabulary?\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print(augment_prompt(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPNBZlRPGlDB",
        "outputId": "8d453129-f6c5-4553-877f-b692c337efdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Baichuan 2 vocabulary size is 125,696.\n"
          ]
        }
      ],
      "source": [
        "# 创建prompt\n",
        "prompt = HumanMessage(\n",
        "    content=augment_prompt(query)\n",
        ")\n",
        "\n",
        "messages.append(prompt)\n",
        "\n",
        "res = chat(messages)\n",
        "\n",
        "print(res.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpwaPwJteHz3"
      },
      "source": [
        "### 没有OPENAI api key怎么办 创建一个非openai的对话模型  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgKpiexG-AS_"
      },
      "source": [
        "\n",
        "1.   embedding模型  \n",
        "2.   chat模型\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ExJrgFacesTo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/45/2d/1151b371f28caae565ad384fdc38198f1165571870217aedda230b9d7497/sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/96/f2/25b27b396af03d5b64e61976b14f7209e2939e9e806c10749b6d277c273e/transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
            "     ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
            "     -- ------------------------------------- 0.5/10.5 MB 2.8 MB/s eta 0:00:04\n",
            "     --- ------------------------------------ 0.8/10.5 MB 3.0 MB/s eta 0:00:04\n",
            "     ------ --------------------------------- 1.6/10.5 MB 2.4 MB/s eta 0:00:04\n",
            "     -------- ------------------------------- 2.1/10.5 MB 2.6 MB/s eta 0:00:04\n",
            "     ---------- ----------------------------- 2.6/10.5 MB 2.6 MB/s eta 0:00:04\n",
            "     ------------ --------------------------- 3.1/10.5 MB 2.7 MB/s eta 0:00:03\n",
            "     --------------- ------------------------ 3.9/10.5 MB 2.8 MB/s eta 0:00:03\n",
            "     ----------------- ---------------------- 4.5/10.5 MB 2.7 MB/s eta 0:00:03\n",
            "     -------------------- ------------------- 5.2/10.5 MB 2.7 MB/s eta 0:00:02\n",
            "     --------------------- ------------------ 5.5/10.5 MB 2.8 MB/s eta 0:00:02\n",
            "     ----------------------- ---------------- 6.0/10.5 MB 2.6 MB/s eta 0:00:02\n",
            "     ------------------------- -------------- 6.6/10.5 MB 2.6 MB/s eta 0:00:02\n",
            "     --------------------------- ------------ 7.1/10.5 MB 2.6 MB/s eta 0:00:02\n",
            "     ----------------------------- ---------- 7.6/10.5 MB 2.6 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 8.1/10.5 MB 2.5 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 8.1/10.5 MB 2.5 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 8.4/10.5 MB 2.4 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 8.9/10.5 MB 2.3 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 9.2/10.5 MB 2.3 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 9.7/10.5 MB 2.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 10.5/10.5 MB 2.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
            "Collecting torch>=1.11.0 (from sentence-transformers)\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/f9/91/3d709cfc5e15995fb3fe7a6b564ce42280d3a55676dad672205e94f34ac9/torch-2.7.1-cp310-cp310-win_amd64.whl (216.1 MB)\n",
            "     ---------------------------------------- 0.0/216.1 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.5/216.1 MB 2.4 MB/s eta 0:01:31\n",
            "     ---------------------------------------- 1.0/216.1 MB 2.5 MB/s eta 0:01:26\n",
            "     ---------------------------------------- 1.6/216.1 MB 2.5 MB/s eta 0:01:28\n",
            "     ---------------------------------------- 2.1/216.1 MB 2.7 MB/s eta 0:01:21\n",
            "     ---------------------------------------- 2.6/216.1 MB 2.7 MB/s eta 0:01:18\n",
            "      --------------------------------------- 3.7/216.1 MB 3.0 MB/s eta 0:01:12\n",
            "      --------------------------------------- 4.5/216.1 MB 3.1 MB/s eta 0:01:09\n",
            "      --------------------------------------- 5.2/216.1 MB 3.2 MB/s eta 0:01:07\n",
            "     - -------------------------------------- 5.8/216.1 MB 3.1 MB/s eta 0:01:08\n",
            "     - -------------------------------------- 6.3/216.1 MB 3.1 MB/s eta 0:01:08\n",
            "     - -------------------------------------- 6.6/216.1 MB 3.0 MB/s eta 0:01:11\n",
            "     - -------------------------------------- 7.3/216.1 MB 2.9 MB/s eta 0:01:12\n",
            "     - -------------------------------------- 7.9/216.1 MB 2.9 MB/s eta 0:01:13\n",
            "     - -------------------------------------- 8.4/216.1 MB 2.9 MB/s eta 0:01:13\n",
            "     - -------------------------------------- 8.9/216.1 MB 2.8 MB/s eta 0:01:14\n",
            "     - -------------------------------------- 9.4/216.1 MB 2.8 MB/s eta 0:01:13\n",
            "     - ------------------------------------- 10.0/216.1 MB 2.9 MB/s eta 0:01:13\n",
            "     - ------------------------------------- 10.5/216.1 MB 2.8 MB/s eta 0:01:13\n",
            "     - ------------------------------------- 11.0/216.1 MB 2.8 MB/s eta 0:01:14\n",
            "     -- ------------------------------------ 11.5/216.1 MB 2.8 MB/s eta 0:01:15\n",
            "     -- ------------------------------------ 12.1/216.1 MB 2.7 MB/s eta 0:01:15\n",
            "     -- ------------------------------------ 12.6/216.1 MB 2.8 MB/s eta 0:01:14\n",
            "     -- ------------------------------------ 12.8/216.1 MB 2.7 MB/s eta 0:01:14\n",
            "     -- ------------------------------------ 13.4/216.1 MB 2.7 MB/s eta 0:01:17\n",
            "     -- ------------------------------------ 13.6/216.1 MB 2.6 MB/s eta 0:01:18\n",
            "     -- ------------------------------------ 14.2/216.1 MB 2.6 MB/s eta 0:01:17\n",
            "     -- ------------------------------------ 14.7/216.1 MB 2.6 MB/s eta 0:01:19\n",
            "     -- ------------------------------------ 14.9/216.1 MB 2.5 MB/s eta 0:01:20\n",
            "     -- ------------------------------------ 15.5/216.1 MB 2.5 MB/s eta 0:01:20\n",
            "     -- ------------------------------------ 16.0/216.1 MB 2.5 MB/s eta 0:01:20\n",
            "     -- ------------------------------------ 16.5/216.1 MB 2.5 MB/s eta 0:01:19\n",
            "     --- ----------------------------------- 17.0/216.1 MB 2.5 MB/s eta 0:01:19\n",
            "     --- ----------------------------------- 17.3/216.1 MB 2.5 MB/s eta 0:01:21\n",
            "     --- ----------------------------------- 17.8/216.1 MB 2.5 MB/s eta 0:01:21\n",
            "     --- ----------------------------------- 18.1/216.1 MB 2.5 MB/s eta 0:01:21\n",
            "     --- ----------------------------------- 18.6/216.1 MB 2.4 MB/s eta 0:01:21\n",
            "     --- ----------------------------------- 18.9/216.1 MB 2.4 MB/s eta 0:01:22\n",
            "     --- ----------------------------------- 19.4/216.1 MB 2.4 MB/s eta 0:01:22\n",
            "     --- ----------------------------------- 19.9/216.1 MB 2.4 MB/s eta 0:01:22\n",
            "     --- ----------------------------------- 20.2/216.1 MB 2.4 MB/s eta 0:01:23\n",
            "     --- ----------------------------------- 20.4/216.1 MB 2.4 MB/s eta 0:01:23\n",
            "     --- ----------------------------------- 20.4/216.1 MB 2.4 MB/s eta 0:01:23\n",
            "     --- ----------------------------------- 20.4/216.1 MB 2.4 MB/s eta 0:01:23\n",
            "     --- ----------------------------------- 20.7/216.1 MB 2.2 MB/s eta 0:01:29\n",
            "     --- ----------------------------------- 20.7/216.1 MB 2.2 MB/s eta 0:01:29\n",
            "     --- ----------------------------------- 21.2/216.1 MB 2.2 MB/s eta 0:01:30\n",
            "     --- ----------------------------------- 21.8/216.1 MB 2.2 MB/s eta 0:01:29\n",
            "     --- ----------------------------------- 22.0/216.1 MB 2.2 MB/s eta 0:01:30\n",
            "     --- ----------------------------------- 22.0/216.1 MB 2.2 MB/s eta 0:01:30\n",
            "     ---- ---------------------------------- 22.3/216.1 MB 2.1 MB/s eta 0:01:33\n",
            "     ---- ---------------------------------- 22.5/216.1 MB 2.1 MB/s eta 0:01:33\n",
            "     ---- ---------------------------------- 22.8/216.1 MB 2.1 MB/s eta 0:01:34\n",
            "     ---- ---------------------------------- 23.1/216.1 MB 2.0 MB/s eta 0:01:35\n",
            "     ---- ---------------------------------- 23.6/216.1 MB 2.0 MB/s eta 0:01:35\n",
            "     ---- ---------------------------------- 24.1/216.1 MB 2.1 MB/s eta 0:01:34\n",
            "     ---- ---------------------------------- 24.6/216.1 MB 2.1 MB/s eta 0:01:33\n",
            "     ---- ---------------------------------- 24.9/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ---- ---------------------------------- 25.2/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ---- ---------------------------------- 25.7/216.1 MB 2.1 MB/s eta 0:01:33\n",
            "     ---- ---------------------------------- 26.2/216.1 MB 2.0 MB/s eta 0:01:33\n",
            "     ---- ---------------------------------- 26.5/216.1 MB 2.0 MB/s eta 0:01:33\n",
            "     ---- ---------------------------------- 26.7/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ---- ---------------------------------- 27.3/216.1 MB 2.0 MB/s eta 0:01:33\n",
            "     ----- --------------------------------- 27.8/216.1 MB 2.0 MB/s eta 0:01:33\n",
            "     ----- --------------------------------- 28.0/216.1 MB 2.0 MB/s eta 0:01:33\n",
            "     ----- --------------------------------- 28.6/216.1 MB 2.0 MB/s eta 0:01:33\n",
            "     ----- --------------------------------- 28.8/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ----- --------------------------------- 29.1/216.1 MB 2.0 MB/s eta 0:01:33\n",
            "     ----- --------------------------------- 29.4/216.1 MB 2.0 MB/s eta 0:01:33\n",
            "     ----- --------------------------------- 29.6/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ----- --------------------------------- 30.1/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ----- --------------------------------- 30.4/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ----- --------------------------------- 30.7/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ----- --------------------------------- 31.2/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ----- --------------------------------- 31.5/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ----- --------------------------------- 31.7/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ----- --------------------------------- 32.0/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ----- --------------------------------- 32.2/216.1 MB 2.0 MB/s eta 0:01:34\n",
            "     ----- --------------------------------- 32.5/216.1 MB 1.9 MB/s eta 0:01:35\n",
            "     ----- --------------------------------- 32.8/216.1 MB 1.9 MB/s eta 0:01:36\n",
            "     ------ -------------------------------- 33.6/216.1 MB 1.9 MB/s eta 0:01:34\n",
            "     ------ -------------------------------- 33.8/216.1 MB 1.9 MB/s eta 0:01:34\n",
            "     ------ -------------------------------- 34.3/216.1 MB 1.9 MB/s eta 0:01:34\n",
            "     ------ -------------------------------- 34.6/216.1 MB 1.9 MB/s eta 0:01:34\n",
            "     ------ -------------------------------- 35.1/216.1 MB 1.9 MB/s eta 0:01:34\n",
            "     ------ -------------------------------- 35.7/216.1 MB 2.0 MB/s eta 0:01:33\n",
            "     ------ -------------------------------- 36.4/216.1 MB 2.0 MB/s eta 0:01:32\n",
            "     ------ -------------------------------- 37.2/216.1 MB 2.0 MB/s eta 0:01:31\n",
            "     ------ -------------------------------- 37.7/216.1 MB 2.0 MB/s eta 0:01:30\n",
            "     ------ -------------------------------- 38.3/216.1 MB 2.0 MB/s eta 0:01:30\n",
            "     ------- ------------------------------- 38.8/216.1 MB 2.0 MB/s eta 0:01:29\n",
            "     ------- ------------------------------- 39.3/216.1 MB 2.0 MB/s eta 0:01:29\n",
            "     ------- ------------------------------- 39.6/216.1 MB 2.0 MB/s eta 0:01:29\n",
            "     ------- ------------------------------- 40.1/216.1 MB 2.0 MB/s eta 0:01:29\n",
            "     ------- ------------------------------- 40.4/216.1 MB 2.0 MB/s eta 0:01:29\n",
            "     ------- ------------------------------- 40.9/216.1 MB 2.0 MB/s eta 0:01:28\n",
            "     ------- ------------------------------- 41.4/216.1 MB 2.0 MB/s eta 0:01:28\n",
            "     ------- ------------------------------- 41.7/216.1 MB 2.0 MB/s eta 0:01:28\n",
            "     ------- ------------------------------- 42.2/216.1 MB 2.0 MB/s eta 0:01:28\n",
            "     ------- ------------------------------- 42.7/216.1 MB 2.0 MB/s eta 0:01:27\n",
            "     ------- ------------------------------- 43.0/216.1 MB 2.0 MB/s eta 0:01:27\n",
            "     ------- ------------------------------- 43.3/216.1 MB 2.0 MB/s eta 0:01:27\n",
            "     ------- ------------------------------- 43.8/216.1 MB 2.0 MB/s eta 0:01:27\n",
            "     ------- ------------------------------- 44.3/216.1 MB 2.0 MB/s eta 0:01:26\n",
            "     -------- ------------------------------ 44.6/216.1 MB 2.0 MB/s eta 0:01:26\n",
            "     -------- ------------------------------ 45.1/216.1 MB 2.0 MB/s eta 0:01:26\n",
            "     -------- ------------------------------ 45.6/216.1 MB 2.0 MB/s eta 0:01:26\n",
            "     -------- ------------------------------ 45.9/216.1 MB 2.0 MB/s eta 0:01:26\n",
            "     -------- ------------------------------ 46.7/216.1 MB 2.0 MB/s eta 0:01:25\n",
            "     -------- ------------------------------ 47.2/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     -------- ------------------------------ 47.7/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     -------- ------------------------------ 48.0/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     -------- ------------------------------ 48.0/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     -------- ------------------------------ 48.5/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     -------- ------------------------------ 48.8/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     -------- ------------------------------ 49.3/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     -------- ------------------------------ 49.5/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     -------- ------------------------------ 49.8/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     --------- ----------------------------- 50.3/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     --------- ----------------------------- 50.6/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     --------- ----------------------------- 51.1/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     --------- ----------------------------- 51.4/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     --------- ----------------------------- 51.6/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     --------- ----------------------------- 52.2/216.1 MB 2.0 MB/s eta 0:01:24\n",
            "     --------- ----------------------------- 53.0/216.1 MB 2.0 MB/s eta 0:01:23\n",
            "     --------- ----------------------------- 53.5/216.1 MB 2.0 MB/s eta 0:01:22\n",
            "     --------- ----------------------------- 54.0/216.1 MB 2.0 MB/s eta 0:01:22\n",
            "     --------- ----------------------------- 54.5/216.1 MB 2.0 MB/s eta 0:01:22\n",
            "     --------- ----------------------------- 54.8/216.1 MB 2.0 MB/s eta 0:01:21\n",
            "     --------- ----------------------------- 55.3/216.1 MB 2.0 MB/s eta 0:01:21\n",
            "     ---------- ---------------------------- 55.8/216.1 MB 2.0 MB/s eta 0:01:21\n",
            "     ---------- ---------------------------- 56.4/216.1 MB 2.0 MB/s eta 0:01:20\n",
            "     ---------- ---------------------------- 57.1/216.1 MB 2.0 MB/s eta 0:01:20\n",
            "     ---------- ---------------------------- 57.7/216.1 MB 2.0 MB/s eta 0:01:19\n",
            "     ---------- ---------------------------- 57.9/216.1 MB 2.0 MB/s eta 0:01:19\n",
            "     ---------- ---------------------------- 58.5/216.1 MB 2.0 MB/s eta 0:01:19\n",
            "     ---------- ---------------------------- 58.7/216.1 MB 2.0 MB/s eta 0:01:19\n",
            "     ---------- ---------------------------- 59.2/216.1 MB 2.0 MB/s eta 0:01:19\n",
            "     ---------- ---------------------------- 59.8/216.1 MB 2.0 MB/s eta 0:01:18\n",
            "     ---------- ---------------------------- 60.3/216.1 MB 2.0 MB/s eta 0:01:18\n",
            "     ---------- ---------------------------- 60.3/216.1 MB 2.0 MB/s eta 0:01:18\n",
            "     ---------- ---------------------------- 60.8/216.1 MB 2.0 MB/s eta 0:01:18\n",
            "     ----------- --------------------------- 61.3/216.1 MB 2.0 MB/s eta 0:01:18\n",
            "     ----------- --------------------------- 61.9/216.1 MB 2.0 MB/s eta 0:01:18\n",
            "     ----------- --------------------------- 62.1/216.1 MB 2.0 MB/s eta 0:01:18\n",
            "     ----------- --------------------------- 62.4/216.1 MB 2.0 MB/s eta 0:01:18\n",
            "     ----------- --------------------------- 62.7/216.1 MB 2.0 MB/s eta 0:01:19\n",
            "     ----------- --------------------------- 62.9/216.1 MB 1.9 MB/s eta 0:01:19\n",
            "     ----------- --------------------------- 63.2/216.1 MB 1.9 MB/s eta 0:01:20\n",
            "     ----------- --------------------------- 63.7/216.1 MB 1.9 MB/s eta 0:01:20\n",
            "     ----------- --------------------------- 63.7/216.1 MB 1.9 MB/s eta 0:01:20\n",
            "     ----------- --------------------------- 63.7/216.1 MB 1.9 MB/s eta 0:01:20\n",
            "     ----------- --------------------------- 64.0/216.1 MB 1.9 MB/s eta 0:01:22\n",
            "     ----------- --------------------------- 64.2/216.1 MB 1.9 MB/s eta 0:01:22\n",
            "     ----------- --------------------------- 65.0/216.1 MB 1.9 MB/s eta 0:01:21\n",
            "     ----------- --------------------------- 65.5/216.1 MB 1.9 MB/s eta 0:01:21\n",
            "     ----------- --------------------------- 66.1/216.1 MB 1.9 MB/s eta 0:01:21\n",
            "     ----------- --------------------------- 66.3/216.1 MB 1.9 MB/s eta 0:01:21\n",
            "     ------------ -------------------------- 66.8/216.1 MB 1.9 MB/s eta 0:01:21\n",
            "     ------------ -------------------------- 67.4/216.1 MB 1.9 MB/s eta 0:01:21\n",
            "     ------------ -------------------------- 68.2/216.1 MB 1.9 MB/s eta 0:01:20\n",
            "     ------------ -------------------------- 68.7/216.1 MB 1.9 MB/s eta 0:01:20\n",
            "     ------------ -------------------------- 69.5/216.1 MB 1.9 MB/s eta 0:01:19\n",
            "     ------------ -------------------------- 70.0/216.1 MB 1.9 MB/s eta 0:01:18\n",
            "     ------------ -------------------------- 70.5/216.1 MB 1.9 MB/s eta 0:01:18\n",
            "     ------------ -------------------------- 71.3/216.1 MB 1.9 MB/s eta 0:01:17\n",
            "     ------------ -------------------------- 71.8/216.1 MB 1.9 MB/s eta 0:01:16\n",
            "     ------------- ------------------------- 72.6/216.1 MB 1.9 MB/s eta 0:01:15\n",
            "     ------------- ------------------------- 73.4/216.1 MB 1.9 MB/s eta 0:01:14\n",
            "     ------------- ------------------------- 73.9/216.1 MB 1.9 MB/s eta 0:01:14\n",
            "     ------------- ------------------------- 74.4/216.1 MB 1.9 MB/s eta 0:01:14\n",
            "     ------------- ------------------------- 75.2/216.1 MB 1.9 MB/s eta 0:01:13\n",
            "     ------------- ------------------------- 75.8/216.1 MB 2.0 MB/s eta 0:01:12\n",
            "     ------------- ------------------------- 76.3/216.1 MB 1.9 MB/s eta 0:01:12\n",
            "     ------------- ------------------------- 76.8/216.1 MB 2.0 MB/s eta 0:01:12\n",
            "     ------------- ------------------------- 77.1/216.1 MB 2.0 MB/s eta 0:01:12\n",
            "     -------------- ------------------------ 77.6/216.1 MB 1.9 MB/s eta 0:01:12\n",
            "     -------------- ------------------------ 77.9/216.1 MB 1.9 MB/s eta 0:01:12\n",
            "     -------------- ------------------------ 78.6/216.1 MB 2.0 MB/s eta 0:01:11\n",
            "     -------------- ------------------------ 78.9/216.1 MB 2.0 MB/s eta 0:01:10\n",
            "     -------------- ------------------------ 79.7/216.1 MB 2.0 MB/s eta 0:01:08\n",
            "     -------------- ------------------------ 80.2/216.1 MB 2.0 MB/s eta 0:01:08\n",
            "     -------------- ------------------------ 81.3/216.1 MB 2.0 MB/s eta 0:01:07\n",
            "     -------------- ------------------------ 82.1/216.1 MB 2.1 MB/s eta 0:01:06\n",
            "     -------------- ------------------------ 82.8/216.1 MB 2.1 MB/s eta 0:01:05\n",
            "     --------------- ----------------------- 83.4/216.1 MB 2.1 MB/s eta 0:01:05\n",
            "     --------------- ----------------------- 84.1/216.1 MB 2.1 MB/s eta 0:01:04\n",
            "     --------------- ----------------------- 85.2/216.1 MB 2.1 MB/s eta 0:01:03\n",
            "     --------------- ----------------------- 86.0/216.1 MB 2.1 MB/s eta 0:01:01\n",
            "     --------------- ----------------------- 87.0/216.1 MB 2.2 MB/s eta 0:01:00\n",
            "     --------------- ----------------------- 87.6/216.1 MB 2.2 MB/s eta 0:01:00\n",
            "     --------------- ----------------------- 88.3/216.1 MB 2.2 MB/s eta 0:00:59\n",
            "     ---------------- ---------------------- 89.1/216.1 MB 2.2 MB/s eta 0:00:58\n",
            "     ---------------- ---------------------- 89.9/216.1 MB 2.2 MB/s eta 0:00:58\n",
            "     ---------------- ---------------------- 90.2/216.1 MB 2.2 MB/s eta 0:00:58\n",
            "     ---------------- ---------------------- 91.2/216.1 MB 2.2 MB/s eta 0:00:57\n",
            "     ---------------- ---------------------- 91.8/216.1 MB 2.2 MB/s eta 0:00:56\n",
            "     ---------------- ---------------------- 92.0/216.1 MB 2.2 MB/s eta 0:00:56\n",
            "     ---------------- ---------------------- 92.5/216.1 MB 2.2 MB/s eta 0:00:56\n",
            "     ---------------- ---------------------- 93.1/216.1 MB 2.2 MB/s eta 0:00:56\n",
            "     ---------------- ---------------------- 93.6/216.1 MB 2.2 MB/s eta 0:00:55\n",
            "     ---------------- ---------------------- 94.1/216.1 MB 2.2 MB/s eta 0:00:55\n",
            "     ----------------- --------------------- 94.6/216.1 MB 2.2 MB/s eta 0:00:55\n",
            "     ----------------- --------------------- 95.2/216.1 MB 2.2 MB/s eta 0:00:54\n",
            "     ----------------- --------------------- 95.9/216.1 MB 2.3 MB/s eta 0:00:54\n",
            "     ----------------- --------------------- 96.5/216.1 MB 2.3 MB/s eta 0:00:53\n",
            "     ----------------- --------------------- 96.7/216.1 MB 2.3 MB/s eta 0:00:53\n",
            "     ----------------- --------------------- 97.0/216.1 MB 2.3 MB/s eta 0:00:53\n",
            "     ----------------- --------------------- 97.5/216.1 MB 2.3 MB/s eta 0:00:53\n",
            "     ----------------- --------------------- 97.5/216.1 MB 2.3 MB/s eta 0:00:53\n",
            "     ----------------- --------------------- 97.8/216.1 MB 2.3 MB/s eta 0:00:53\n",
            "     ----------------- --------------------- 98.3/216.1 MB 2.3 MB/s eta 0:00:53\n",
            "     ----------------- --------------------- 98.6/216.1 MB 2.3 MB/s eta 0:00:52\n",
            "     ----------------- --------------------- 99.1/216.1 MB 2.3 MB/s eta 0:00:52\n",
            "     ----------------- --------------------- 99.6/216.1 MB 2.3 MB/s eta 0:00:52\n",
            "     ----------------- -------------------- 100.1/216.1 MB 2.3 MB/s eta 0:00:51\n",
            "     ----------------- -------------------- 100.4/216.1 MB 2.3 MB/s eta 0:00:51\n",
            "     ----------------- -------------------- 101.2/216.1 MB 2.3 MB/s eta 0:00:51\n",
            "     ----------------- -------------------- 102.0/216.1 MB 2.3 MB/s eta 0:00:50\n",
            "     ------------------ ------------------- 102.5/216.1 MB 2.3 MB/s eta 0:00:49\n",
            "     ------------------ ------------------- 103.0/216.1 MB 2.3 MB/s eta 0:00:49\n",
            "     ------------------ ------------------- 103.8/216.1 MB 2.3 MB/s eta 0:00:49\n",
            "     ------------------ ------------------- 104.3/216.1 MB 2.3 MB/s eta 0:00:48\n",
            "     ------------------ ------------------- 104.9/216.1 MB 2.3 MB/s eta 0:00:48\n",
            "     ------------------ ------------------- 105.4/216.1 MB 2.3 MB/s eta 0:00:48\n",
            "     ------------------ ------------------- 106.4/216.1 MB 2.4 MB/s eta 0:00:47\n",
            "     ------------------ ------------------- 107.2/216.1 MB 2.4 MB/s eta 0:00:47\n",
            "     ------------------ ------------------- 107.5/216.1 MB 2.3 MB/s eta 0:00:47\n",
            "     ------------------- ------------------ 108.3/216.1 MB 2.4 MB/s eta 0:00:46\n",
            "     ------------------- ------------------ 108.8/216.1 MB 2.4 MB/s eta 0:00:46\n",
            "     ------------------- ------------------ 109.1/216.1 MB 2.3 MB/s eta 0:00:46\n",
            "     ------------------- ------------------ 109.8/216.1 MB 2.4 MB/s eta 0:00:46\n",
            "     ------------------- ------------------ 110.4/216.1 MB 2.4 MB/s eta 0:00:45\n",
            "     ------------------- ------------------ 110.6/216.1 MB 2.4 MB/s eta 0:00:45\n",
            "     ------------------- ------------------ 111.4/216.1 MB 2.4 MB/s eta 0:00:45\n",
            "     ------------------- ------------------ 111.7/216.1 MB 2.4 MB/s eta 0:00:45\n",
            "     ------------------- ------------------ 112.2/216.1 MB 2.4 MB/s eta 0:00:44\n",
            "     ------------------- ------------------ 112.7/216.1 MB 2.4 MB/s eta 0:00:44\n",
            "     ------------------- ------------------ 113.2/216.1 MB 2.4 MB/s eta 0:00:44\n",
            "     -------------------- ----------------- 113.8/216.1 MB 2.4 MB/s eta 0:00:44\n",
            "     -------------------- ----------------- 114.3/216.1 MB 2.4 MB/s eta 0:00:43\n",
            "     -------------------- ----------------- 114.8/216.1 MB 2.4 MB/s eta 0:00:43\n",
            "     -------------------- ----------------- 115.1/216.1 MB 2.4 MB/s eta 0:00:43\n",
            "     -------------------- ----------------- 115.3/216.1 MB 2.4 MB/s eta 0:00:43\n",
            "     -------------------- ----------------- 116.1/216.1 MB 2.4 MB/s eta 0:00:42\n",
            "     -------------------- ----------------- 116.7/216.1 MB 2.4 MB/s eta 0:00:42\n",
            "     -------------------- ----------------- 117.2/216.1 MB 2.4 MB/s eta 0:00:42\n",
            "     -------------------- ----------------- 118.0/216.1 MB 2.4 MB/s eta 0:00:41\n",
            "     -------------------- ----------------- 118.5/216.1 MB 2.4 MB/s eta 0:00:41\n",
            "     --------------------- ---------------- 119.5/216.1 MB 2.4 MB/s eta 0:00:41\n",
            "     --------------------- ---------------- 120.3/216.1 MB 2.4 MB/s eta 0:00:40\n",
            "     --------------------- ---------------- 120.8/216.1 MB 2.4 MB/s eta 0:00:40\n",
            "     --------------------- ---------------- 121.4/216.1 MB 2.4 MB/s eta 0:00:39\n",
            "     --------------------- ---------------- 122.2/216.1 MB 2.5 MB/s eta 0:00:39\n",
            "     --------------------- ---------------- 122.9/216.1 MB 2.5 MB/s eta 0:00:38\n",
            "     --------------------- ---------------- 123.5/216.1 MB 2.5 MB/s eta 0:00:38\n",
            "     --------------------- ---------------- 124.3/216.1 MB 2.5 MB/s eta 0:00:37\n",
            "     --------------------- ---------------- 124.8/216.1 MB 2.5 MB/s eta 0:00:37\n",
            "     ---------------------- --------------- 125.3/216.1 MB 2.5 MB/s eta 0:00:37\n",
            "     ---------------------- --------------- 125.6/216.1 MB 2.5 MB/s eta 0:00:37\n",
            "     ---------------------- --------------- 125.6/216.1 MB 2.5 MB/s eta 0:00:37\n",
            "     ---------------------- --------------- 126.4/216.1 MB 2.5 MB/s eta 0:00:36\n",
            "     ---------------------- --------------- 126.9/216.1 MB 2.5 MB/s eta 0:00:36\n",
            "     ---------------------- --------------- 127.9/216.1 MB 2.5 MB/s eta 0:00:35\n",
            "     ---------------------- --------------- 128.7/216.1 MB 2.5 MB/s eta 0:00:35\n",
            "     ---------------------- --------------- 129.5/216.1 MB 2.5 MB/s eta 0:00:35\n",
            "     ---------------------- --------------- 130.3/216.1 MB 2.5 MB/s eta 0:00:34\n",
            "     ----------------------- -------------- 131.1/216.1 MB 2.6 MB/s eta 0:00:34\n",
            "     ----------------------- -------------- 131.6/216.1 MB 2.6 MB/s eta 0:00:34\n",
            "     ----------------------- -------------- 132.1/216.1 MB 2.6 MB/s eta 0:00:33\n",
            "     ----------------------- -------------- 132.6/216.1 MB 2.6 MB/s eta 0:00:33\n",
            "     ----------------------- -------------- 133.4/216.1 MB 2.6 MB/s eta 0:00:33\n",
            "     ----------------------- -------------- 134.2/216.1 MB 2.6 MB/s eta 0:00:32\n",
            "     ----------------------- -------------- 134.7/216.1 MB 2.6 MB/s eta 0:00:32\n",
            "     ----------------------- -------------- 135.0/216.1 MB 2.6 MB/s eta 0:00:32\n",
            "     ----------------------- -------------- 135.5/216.1 MB 2.6 MB/s eta 0:00:32\n",
            "     ----------------------- -------------- 136.1/216.1 MB 2.6 MB/s eta 0:00:32\n",
            "     ------------------------ ------------- 136.6/216.1 MB 2.6 MB/s eta 0:00:31\n",
            "     ------------------------ ------------- 137.1/216.1 MB 2.6 MB/s eta 0:00:31\n",
            "     ------------------------ ------------- 137.1/216.1 MB 2.6 MB/s eta 0:00:31\n",
            "     ------------------------ ------------- 137.4/216.1 MB 2.6 MB/s eta 0:00:31\n",
            "     ------------------------ ------------- 137.6/216.1 MB 2.6 MB/s eta 0:00:31\n",
            "     ------------------------ ------------- 138.1/216.1 MB 2.6 MB/s eta 0:00:31\n",
            "     ------------------------ ------------- 138.7/216.1 MB 2.6 MB/s eta 0:00:31\n",
            "     ------------------------ ------------- 138.9/216.1 MB 2.6 MB/s eta 0:00:31\n",
            "     ------------------------ ------------- 139.2/216.1 MB 2.6 MB/s eta 0:00:30\n",
            "     ------------------------ ------------- 139.7/216.1 MB 2.6 MB/s eta 0:00:30\n",
            "     ------------------------ ------------- 140.5/216.1 MB 2.6 MB/s eta 0:00:30\n",
            "     ------------------------ ------------- 140.8/216.1 MB 2.6 MB/s eta 0:00:29\n",
            "     ------------------------ ------------- 141.3/216.1 MB 2.6 MB/s eta 0:00:29\n",
            "     ------------------------ ------------- 141.6/216.1 MB 2.6 MB/s eta 0:00:29\n",
            "     ------------------------- ------------ 142.3/216.1 MB 2.6 MB/s eta 0:00:28\n",
            "     ------------------------- ------------ 142.9/216.1 MB 2.6 MB/s eta 0:00:28\n",
            "     ------------------------- ------------ 143.1/216.1 MB 2.6 MB/s eta 0:00:28\n",
            "     ------------------------- ------------ 143.7/216.1 MB 2.6 MB/s eta 0:00:28\n",
            "     ------------------------- ------------ 144.2/216.1 MB 2.6 MB/s eta 0:00:28\n",
            "     ------------------------- ------------ 144.4/216.1 MB 2.6 MB/s eta 0:00:28\n",
            "     ------------------------- ------------ 145.0/216.1 MB 2.6 MB/s eta 0:00:28\n",
            "     ------------------------- ------------ 145.5/216.1 MB 2.6 MB/s eta 0:00:27\n",
            "     ------------------------- ------------ 145.8/216.1 MB 2.6 MB/s eta 0:00:27\n",
            "     ------------------------- ------------ 146.3/216.1 MB 2.6 MB/s eta 0:00:27\n",
            "     ------------------------- ------------ 146.5/216.1 MB 2.6 MB/s eta 0:00:27\n",
            "     ------------------------- ------------ 147.1/216.1 MB 2.6 MB/s eta 0:00:27\n",
            "     ------------------------- ------------ 147.3/216.1 MB 2.6 MB/s eta 0:00:27\n",
            "     ------------------------- ------------ 147.8/216.1 MB 2.6 MB/s eta 0:00:27\n",
            "     -------------------------- ----------- 148.1/216.1 MB 2.6 MB/s eta 0:00:27\n",
            "     -------------------------- ----------- 148.9/216.1 MB 2.6 MB/s eta 0:00:27\n",
            "     -------------------------- ----------- 149.4/216.1 MB 2.6 MB/s eta 0:00:26\n",
            "     -------------------------- ----------- 149.7/216.1 MB 2.6 MB/s eta 0:00:26\n",
            "     -------------------------- ----------- 150.2/216.1 MB 2.6 MB/s eta 0:00:26\n",
            "     -------------------------- ----------- 151.0/216.1 MB 2.6 MB/s eta 0:00:26\n",
            "     -------------------------- ----------- 151.5/216.1 MB 2.5 MB/s eta 0:00:26\n",
            "     -------------------------- ----------- 152.3/216.1 MB 2.6 MB/s eta 0:00:25\n",
            "     -------------------------- ----------- 152.8/216.1 MB 2.6 MB/s eta 0:00:25\n",
            "     -------------------------- ----------- 153.4/216.1 MB 2.6 MB/s eta 0:00:25\n",
            "     --------------------------- ---------- 153.9/216.1 MB 2.6 MB/s eta 0:00:25\n",
            "     --------------------------- ---------- 154.4/216.1 MB 2.6 MB/s eta 0:00:24\n",
            "     --------------------------- ---------- 154.9/216.1 MB 2.6 MB/s eta 0:00:24\n",
            "     --------------------------- ---------- 155.5/216.1 MB 2.6 MB/s eta 0:00:24\n",
            "     --------------------------- ---------- 156.2/216.1 MB 2.6 MB/s eta 0:00:24\n",
            "     --------------------------- ---------- 156.8/216.1 MB 2.6 MB/s eta 0:00:23\n",
            "     --------------------------- ---------- 157.5/216.1 MB 2.6 MB/s eta 0:00:23\n",
            "     --------------------------- ---------- 157.8/216.1 MB 2.6 MB/s eta 0:00:23\n",
            "     --------------------------- ---------- 158.6/216.1 MB 2.6 MB/s eta 0:00:23\n",
            "     ---------------------------- --------- 159.4/216.1 MB 2.6 MB/s eta 0:00:23\n",
            "     ---------------------------- --------- 159.6/216.1 MB 2.6 MB/s eta 0:00:23\n",
            "     ---------------------------- --------- 160.4/216.1 MB 2.6 MB/s eta 0:00:22\n",
            "     ---------------------------- --------- 161.0/216.1 MB 2.5 MB/s eta 0:00:22\n",
            "     ---------------------------- --------- 161.2/216.1 MB 2.5 MB/s eta 0:00:22\n",
            "     ---------------------------- --------- 162.0/216.1 MB 2.5 MB/s eta 0:00:22\n",
            "     ---------------------------- --------- 162.5/216.1 MB 2.5 MB/s eta 0:00:22\n",
            "     ---------------------------- --------- 163.3/216.1 MB 2.5 MB/s eta 0:00:22\n",
            "     ---------------------------- --------- 163.8/216.1 MB 2.5 MB/s eta 0:00:21\n",
            "     ---------------------------- --------- 164.4/216.1 MB 2.5 MB/s eta 0:00:21\n",
            "     ---------------------------- --------- 164.9/216.1 MB 2.5 MB/s eta 0:00:21\n",
            "     ----------------------------- -------- 165.4/216.1 MB 2.5 MB/s eta 0:00:21\n",
            "     ----------------------------- -------- 166.2/216.1 MB 2.5 MB/s eta 0:00:21\n",
            "     ----------------------------- -------- 166.5/216.1 MB 2.5 MB/s eta 0:00:20\n",
            "     ----------------------------- -------- 167.0/216.1 MB 2.5 MB/s eta 0:00:20\n",
            "     ----------------------------- -------- 167.8/216.1 MB 2.5 MB/s eta 0:00:20\n",
            "     ----------------------------- -------- 168.3/216.1 MB 2.5 MB/s eta 0:00:20\n",
            "     ----------------------------- -------- 168.8/216.1 MB 2.5 MB/s eta 0:00:19\n",
            "     ----------------------------- -------- 169.3/216.1 MB 2.5 MB/s eta 0:00:19\n",
            "     ----------------------------- -------- 169.6/216.1 MB 2.5 MB/s eta 0:00:19\n",
            "     ----------------------------- -------- 170.1/216.1 MB 2.5 MB/s eta 0:00:19\n",
            "     ------------------------------ ------- 170.7/216.1 MB 2.5 MB/s eta 0:00:19\n",
            "     ------------------------------ ------- 171.4/216.1 MB 2.5 MB/s eta 0:00:18\n",
            "     ------------------------------ ------- 171.7/216.1 MB 2.5 MB/s eta 0:00:18\n",
            "     ------------------------------ ------- 172.0/216.1 MB 2.5 MB/s eta 0:00:18\n",
            "     ------------------------------ ------- 172.2/216.1 MB 2.5 MB/s eta 0:00:18\n",
            "     ------------------------------ ------- 172.5/216.1 MB 2.5 MB/s eta 0:00:18\n",
            "     ------------------------------ ------- 172.8/216.1 MB 2.5 MB/s eta 0:00:18\n",
            "     ------------------------------ ------- 173.3/216.1 MB 2.5 MB/s eta 0:00:18\n",
            "     ------------------------------ ------- 173.8/216.1 MB 2.5 MB/s eta 0:00:17\n",
            "     ------------------------------ ------- 174.6/216.1 MB 2.5 MB/s eta 0:00:17\n",
            "     ------------------------------ ------- 174.9/216.1 MB 2.5 MB/s eta 0:00:17\n",
            "     ------------------------------ ------- 175.1/216.1 MB 2.5 MB/s eta 0:00:17\n",
            "     ------------------------------ ------- 175.6/216.1 MB 2.5 MB/s eta 0:00:17\n",
            "     ------------------------------ ------- 175.9/216.1 MB 2.5 MB/s eta 0:00:17\n",
            "     ------------------------------- ------ 176.7/216.1 MB 2.5 MB/s eta 0:00:16\n",
            "     ------------------------------- ------ 176.7/216.1 MB 2.5 MB/s eta 0:00:16\n",
            "     ------------------------------- ------ 176.7/216.1 MB 2.5 MB/s eta 0:00:16\n",
            "     ------------------------------- ------ 176.7/216.1 MB 2.5 MB/s eta 0:00:16\n",
            "     ------------------------------- ------ 176.7/216.1 MB 2.5 MB/s eta 0:00:16\n",
            "     ------------------------------- ------ 177.2/216.1 MB 2.4 MB/s eta 0:00:17\n",
            "     ------------------------------- ------ 177.7/216.1 MB 2.4 MB/s eta 0:00:16\n",
            "     ------------------------------- ------ 178.3/216.1 MB 2.4 MB/s eta 0:00:16\n",
            "     ------------------------------- ------ 178.8/216.1 MB 2.4 MB/s eta 0:00:16\n",
            "     ------------------------------- ------ 179.3/216.1 MB 2.4 MB/s eta 0:00:16\n",
            "     ------------------------------- ------ 180.1/216.1 MB 2.4 MB/s eta 0:00:16\n",
            "     ------------------------------- ------ 180.6/216.1 MB 2.4 MB/s eta 0:00:15\n",
            "     ------------------------------- ------ 181.4/216.1 MB 2.4 MB/s eta 0:00:15\n",
            "     ------------------------------- ------ 181.7/216.1 MB 2.4 MB/s eta 0:00:15\n",
            "     -------------------------------- ----- 182.5/216.1 MB 2.4 MB/s eta 0:00:14\n",
            "     -------------------------------- ----- 183.0/216.1 MB 2.4 MB/s eta 0:00:14\n",
            "     -------------------------------- ----- 184.0/216.1 MB 2.4 MB/s eta 0:00:14\n",
            "     -------------------------------- ----- 184.3/216.1 MB 2.4 MB/s eta 0:00:14\n",
            "     -------------------------------- ----- 184.8/216.1 MB 2.4 MB/s eta 0:00:13\n",
            "     -------------------------------- ----- 185.6/216.1 MB 2.4 MB/s eta 0:00:13\n",
            "     -------------------------------- ----- 186.1/216.1 MB 2.4 MB/s eta 0:00:13\n",
            "     -------------------------------- ----- 186.6/216.1 MB 2.4 MB/s eta 0:00:13\n",
            "     -------------------------------- ----- 186.6/216.1 MB 2.4 MB/s eta 0:00:13\n",
            "     -------------------------------- ----- 187.2/216.1 MB 2.4 MB/s eta 0:00:12\n",
            "     --------------------------------- ---- 187.7/216.1 MB 2.4 MB/s eta 0:00:12\n",
            "     --------------------------------- ---- 188.2/216.1 MB 2.4 MB/s eta 0:00:12\n",
            "     --------------------------------- ---- 189.0/216.1 MB 2.4 MB/s eta 0:00:12\n",
            "     --------------------------------- ---- 189.5/216.1 MB 2.4 MB/s eta 0:00:11\n",
            "     --------------------------------- ---- 189.8/216.1 MB 2.4 MB/s eta 0:00:11\n",
            "     --------------------------------- ---- 190.6/216.1 MB 2.4 MB/s eta 0:00:11\n",
            "     --------------------------------- ---- 191.1/216.1 MB 2.4 MB/s eta 0:00:11\n",
            "     --------------------------------- ---- 191.9/216.1 MB 2.4 MB/s eta 0:00:10\n",
            "     --------------------------------- ---- 192.2/216.1 MB 2.4 MB/s eta 0:00:10\n",
            "     --------------------------------- ---- 192.7/216.1 MB 2.4 MB/s eta 0:00:10\n",
            "     --------------------------------- ---- 193.2/216.1 MB 2.4 MB/s eta 0:00:10\n",
            "     --------------------------------- ---- 193.2/216.1 MB 2.4 MB/s eta 0:00:10\n",
            "     ---------------------------------- --- 193.5/216.1 MB 2.4 MB/s eta 0:00:10\n",
            "     ---------------------------------- --- 193.7/216.1 MB 2.4 MB/s eta 0:00:10\n",
            "     ---------------------------------- --- 194.0/216.1 MB 2.3 MB/s eta 0:00:10\n",
            "     ---------------------------------- --- 194.2/216.1 MB 2.3 MB/s eta 0:00:10\n",
            "     ---------------------------------- --- 195.0/216.1 MB 2.3 MB/s eta 0:00:10\n",
            "     ---------------------------------- --- 195.6/216.1 MB 2.3 MB/s eta 0:00:09\n",
            "     ---------------------------------- --- 196.1/216.1 MB 2.4 MB/s eta 0:00:09\n",
            "     ---------------------------------- --- 196.6/216.1 MB 2.4 MB/s eta 0:00:09\n",
            "     ---------------------------------- --- 196.9/216.1 MB 2.3 MB/s eta 0:00:09\n",
            "     ---------------------------------- --- 197.4/216.1 MB 2.3 MB/s eta 0:00:08\n",
            "     ---------------------------------- --- 197.9/216.1 MB 2.3 MB/s eta 0:00:08\n",
            "     ---------------------------------- --- 198.4/216.1 MB 2.3 MB/s eta 0:00:08\n",
            "     ---------------------------------- --- 199.0/216.1 MB 2.3 MB/s eta 0:00:08\n",
            "     ----------------------------------- -- 199.5/216.1 MB 2.3 MB/s eta 0:00:08\n",
            "     ----------------------------------- -- 200.0/216.1 MB 2.3 MB/s eta 0:00:07\n",
            "     ----------------------------------- -- 200.8/216.1 MB 2.3 MB/s eta 0:00:07\n",
            "     ----------------------------------- -- 201.6/216.1 MB 2.3 MB/s eta 0:00:07\n",
            "     ----------------------------------- -- 201.9/216.1 MB 2.3 MB/s eta 0:00:07\n",
            "     ----------------------------------- -- 202.4/216.1 MB 2.3 MB/s eta 0:00:06\n",
            "     ----------------------------------- -- 202.9/216.1 MB 2.3 MB/s eta 0:00:06\n",
            "     ----------------------------------- -- 203.7/216.1 MB 2.3 MB/s eta 0:00:06\n",
            "     ----------------------------------- -- 204.2/216.1 MB 2.3 MB/s eta 0:00:06\n",
            "     ------------------------------------ - 205.0/216.1 MB 2.3 MB/s eta 0:00:05\n",
            "     ------------------------------------ - 205.5/216.1 MB 2.3 MB/s eta 0:00:05\n",
            "     ------------------------------------ - 206.6/216.1 MB 2.3 MB/s eta 0:00:05\n",
            "     ------------------------------------ - 207.1/216.1 MB 2.3 MB/s eta 0:00:04\n",
            "     ------------------------------------ - 207.9/216.1 MB 2.4 MB/s eta 0:00:04\n",
            "     ------------------------------------ - 208.7/216.1 MB 2.4 MB/s eta 0:00:04\n",
            "     ------------------------------------ - 208.9/216.1 MB 2.4 MB/s eta 0:00:04\n",
            "     ------------------------------------ - 209.5/216.1 MB 2.4 MB/s eta 0:00:03\n",
            "     ------------------------------------ - 210.2/216.1 MB 2.4 MB/s eta 0:00:03\n",
            "     -------------------------------------  210.8/216.1 MB 2.4 MB/s eta 0:00:03\n",
            "     -------------------------------------  211.6/216.1 MB 2.4 MB/s eta 0:00:02\n",
            "     -------------------------------------  212.1/216.1 MB 2.4 MB/s eta 0:00:02\n",
            "     -------------------------------------  213.1/216.1 MB 2.4 MB/s eta 0:00:02\n",
            "     -------------------------------------  214.2/216.1 MB 2.4 MB/s eta 0:00:01\n",
            "     -------------------------------------  215.0/216.1 MB 2.5 MB/s eta 0:00:01\n",
            "     -------------------------------------  215.2/216.1 MB 2.5 MB/s eta 0:00:01\n",
            "     -------------------------------------  216.0/216.1 MB 2.5 MB/s eta 0:00:01\n",
            "     -------------------------------------  216.0/216.1 MB 2.5 MB/s eta 0:00:01\n",
            "     -------------------------------------- 216.1/216.1 MB 2.4 MB/s eta 0:00:00\n",
            "Collecting scikit-learn (from sentence-transformers)\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/4c/bd/99c3ccb49946bd06318fe194a1c54fb7d57ac4fe1c2f4660d86b3a2adf64/scikit_learn-1.7.0-cp310-cp310-win_amd64.whl (10.7 MB)\n",
            "     ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
            "     - -------------------------------------- 0.5/10.7 MB 2.4 MB/s eta 0:00:05\n",
            "     -- ------------------------------------- 0.8/10.7 MB 3.0 MB/s eta 0:00:04\n",
            "     -- ------------------------------------- 0.8/10.7 MB 3.0 MB/s eta 0:00:04\n",
            "     -- ------------------------------------- 0.8/10.7 MB 3.0 MB/s eta 0:00:04\n",
            "     -- ------------------------------------- 0.8/10.7 MB 3.0 MB/s eta 0:00:04\n",
            "     -- ------------------------------------- 0.8/10.7 MB 3.0 MB/s eta 0:00:04\n",
            "     ---- ---------------------------------- 1.3/10.7 MB 828.3 kB/s eta 0:00:12\n",
            "     -------- ------------------------------- 2.4/10.7 MB 1.3 MB/s eta 0:00:07\n",
            "     ------------ --------------------------- 3.4/10.7 MB 1.7 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 3.9/10.7 MB 1.8 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 4.7/10.7 MB 2.0 MB/s eta 0:00:03\n",
            "     --------------------- ------------------ 5.8/10.7 MB 2.3 MB/s eta 0:00:03\n",
            "     ------------------------- -------------- 6.8/10.7 MB 2.5 MB/s eta 0:00:02\n",
            "     ----------------------------- ---------- 7.9/10.7 MB 2.7 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 8.4/10.7 MB 2.7 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 9.2/10.7 MB 2.8 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 10.2/10.7 MB 2.9 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 10.7/10.7 MB 2.9 MB/s eta 0:00:00\n",
            "Collecting scipy (from sentence-transformers)\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/d1/84/55bc4881973d3f79b479a5a2e2df61c8c9a04fcb986a213ac9c02cfb659b/scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
            "     ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.3/41.3 MB ? eta -:--:--\n",
            "     - -------------------------------------- 1.0/41.3 MB 2.6 MB/s eta 0:00:16\n",
            "     - -------------------------------------- 1.8/41.3 MB 3.2 MB/s eta 0:00:13\n",
            "     -- ------------------------------------- 2.6/41.3 MB 3.3 MB/s eta 0:00:12\n",
            "     --- ------------------------------------ 3.1/41.3 MB 3.2 MB/s eta 0:00:12\n",
            "     --- ------------------------------------ 3.7/41.3 MB 3.0 MB/s eta 0:00:13\n",
            "     ---- ----------------------------------- 4.2/41.3 MB 2.8 MB/s eta 0:00:14\n",
            "     ---- ----------------------------------- 5.0/41.3 MB 3.0 MB/s eta 0:00:13\n",
            "     ----- ---------------------------------- 5.5/41.3 MB 2.9 MB/s eta 0:00:13\n",
            "     ------ --------------------------------- 6.6/41.3 MB 3.1 MB/s eta 0:00:12\n",
            "     ------- -------------------------------- 7.3/41.3 MB 3.2 MB/s eta 0:00:11\n",
            "     ------- -------------------------------- 7.6/41.3 MB 3.1 MB/s eta 0:00:11\n",
            "     -------- ------------------------------- 8.7/41.3 MB 3.2 MB/s eta 0:00:11\n",
            "     -------- ------------------------------- 9.2/41.3 MB 3.2 MB/s eta 0:00:11\n",
            "     --------- ------------------------------ 9.7/41.3 MB 3.1 MB/s eta 0:00:11\n",
            "     ---------- ----------------------------- 10.5/41.3 MB 3.1 MB/s eta 0:00:10\n",
            "     ----------- ---------------------------- 11.5/41.3 MB 3.2 MB/s eta 0:00:10\n",
            "     ----------- ---------------------------- 12.3/41.3 MB 3.3 MB/s eta 0:00:09\n",
            "     ------------ --------------------------- 13.1/41.3 MB 3.3 MB/s eta 0:00:09\n",
            "     ------------- -------------------------- 13.9/41.3 MB 3.4 MB/s eta 0:00:09\n",
            "     -------------- ------------------------- 14.7/41.3 MB 3.4 MB/s eta 0:00:08\n",
            "     -------------- ------------------------- 15.5/41.3 MB 3.4 MB/s eta 0:00:08\n",
            "     --------------- ------------------------ 16.3/41.3 MB 3.4 MB/s eta 0:00:08\n",
            "     ---------------- ----------------------- 17.0/41.3 MB 3.5 MB/s eta 0:00:08\n",
            "     ----------------- ---------------------- 18.1/41.3 MB 3.5 MB/s eta 0:00:07\n",
            "     ------------------ --------------------- 18.6/41.3 MB 3.5 MB/s eta 0:00:07\n",
            "     ------------------- -------------------- 19.7/41.3 MB 3.5 MB/s eta 0:00:07\n",
            "     ------------------- -------------------- 20.4/41.3 MB 3.5 MB/s eta 0:00:06\n",
            "     -------------------- ------------------- 21.2/41.3 MB 3.5 MB/s eta 0:00:06\n",
            "     --------------------- ------------------ 22.0/41.3 MB 3.5 MB/s eta 0:00:06\n",
            "     ---------------------- ----------------- 23.1/41.3 MB 3.6 MB/s eta 0:00:06\n",
            "     ----------------------- ---------------- 23.9/41.3 MB 3.6 MB/s eta 0:00:05\n",
            "     ----------------------- ---------------- 24.6/41.3 MB 3.6 MB/s eta 0:00:05\n",
            "     ------------------------ --------------- 25.4/41.3 MB 3.6 MB/s eta 0:00:05\n",
            "     ------------------------- -------------- 26.0/41.3 MB 3.5 MB/s eta 0:00:05\n",
            "     ------------------------- -------------- 26.7/41.3 MB 3.6 MB/s eta 0:00:05\n",
            "     -------------------------- ------------- 27.8/41.3 MB 3.6 MB/s eta 0:00:04\n",
            "     --------------------------- ------------ 28.6/41.3 MB 3.6 MB/s eta 0:00:04\n",
            "     ---------------------------- ----------- 29.4/41.3 MB 3.6 MB/s eta 0:00:04\n",
            "     ----------------------------- ---------- 30.1/41.3 MB 3.6 MB/s eta 0:00:04\n",
            "     ----------------------------- ---------- 30.9/41.3 MB 3.6 MB/s eta 0:00:03\n",
            "     ------------------------------ --------- 31.5/41.3 MB 3.6 MB/s eta 0:00:03\n",
            "     ------------------------------- -------- 32.2/41.3 MB 3.6 MB/s eta 0:00:03\n",
            "     ------------------------------- -------- 32.8/41.3 MB 3.6 MB/s eta 0:00:03\n",
            "     -------------------------------- ------- 33.3/41.3 MB 3.5 MB/s eta 0:00:03\n",
            "     -------------------------------- ------- 33.8/41.3 MB 3.5 MB/s eta 0:00:03\n",
            "     -------------------------------- ------- 33.8/41.3 MB 3.5 MB/s eta 0:00:03\n",
            "     --------------------------------- ------ 34.3/41.3 MB 3.5 MB/s eta 0:00:02\n",
            "     --------------------------------- ------ 34.9/41.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 35.4/41.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 35.7/41.3 MB 3.3 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 35.9/41.3 MB 3.3 MB/s eta 0:00:02\n",
            "     ----------------------------------- ---- 36.7/41.3 MB 3.3 MB/s eta 0:00:02\n",
            "     ------------------------------------ --- 37.5/41.3 MB 3.3 MB/s eta 0:00:02\n",
            "     ------------------------------------ --- 38.0/41.3 MB 3.3 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 39.1/41.3 MB 3.3 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 40.1/41.3 MB 3.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------  41.2/41.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------  41.2/41.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 41.3/41.3 MB 3.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (0.33.0)\n",
            "Collecting Pillow (from sentence-transformers)\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/ed/3c/9831da3edea527c2ed9a09f31a2c04e77cd705847f13b69ca60269eec370/pillow-11.2.1-cp310-cp310-win_amd64.whl (2.7 MB)\n",
            "     ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
            "     ------- -------------------------------- 0.5/2.7 MB 3.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 1.6/2.7 MB 4.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.7/2.7 MB 4.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/69/e2/b011c38e5394c4c18fb5500778a55ec43ad6106126e74723ffaee246f56e/safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "     ------------------ --------------------- 0.8/1.7 MB 2.8 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 1.6/1.7 MB 3.5 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.7/1.7 MB 3.1 MB/s eta 0:00:00\n",
            "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: colorama in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/44/06/e7175d06dd6e9172d4a69a72592cb3f7a996a9c396eee29082826449bbc3/MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda3\\envs\\rag\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.6.15)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/7d/4f/1195bbac8e0c2acc5f740661631d8d750dc38d4a32b23ee5df3cde6f4e0d/joblib-1.5.1-py3-none-any.whl (307 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, safetensors, Pillow, networkx, MarkupSafe, joblib, scikit-learn, jinja2, torch, transformers, sentence-transformers\n",
            "\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   ---------- -----------------------------  3/12 [Pillow]\n",
            "   ---------- -----------------------------  3/12 [Pillow]\n",
            "   ---------- -----------------------------  3/12 [Pillow]\n",
            "   ---------- -----------------------------  3/12 [Pillow]\n",
            "   ---------- -----------------------------  3/12 [Pillow]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   ------------- --------------------------  4/12 [networkx]\n",
            "   -------------------- -------------------  6/12 [joblib]\n",
            "   -------------------- -------------------  6/12 [joblib]\n",
            "   -------------------- -------------------  6/12 [joblib]\n",
            "   -------------------- -------------------  6/12 [joblib]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   ----------------------- ----------------  7/12 [scikit-learn]\n",
            "   -------------------------- -------------  8/12 [jinja2]\n",
            "   -------------------------- -------------  8/12 [jinja2]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   ------------------------------ ---------  9/12 [torch]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   --------------------------------- ------ 10/12 [transformers]\n",
            "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
            "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
            "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
            "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
            "   ---------------------------------------- 12/12 [sentence-transformers]\n",
            "\n",
            "Successfully installed MarkupSafe-3.0.2 Pillow-11.2.1 jinja2-3.1.6 joblib-1.5.1 networkx-3.4.2 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.15.3 sentence-transformers-4.1.0 threadpoolctl-3.6.0 torch-2.7.1 transformers-4.52.4\n"
          ]
        }
      ],
      "source": [
        "! pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "xvD4mIBCHKjG"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "model_name = \"sentence-transformers/sentence-t5-large\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SzFKi_bQehhX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\miniconda3\\envs\\rag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        }
      ],
      "source": [
        "embedding = HuggingFaceEmbeddings(model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "jJP5K7J5ehlB"
      },
      "outputs": [],
      "source": [
        "vectorstore_hf = Chroma.from_documents(documents=docs, embedding=embedding , collection_name=\"huggingface_embed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = vectorstore_hf.similarity_search(query ,k = 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content='a high compression rate for efficient inference,\\nand an appropriately sized vocabulary to ensure\\nadequate training of each word embedding. We\\nhave taken both these aspects into account. We\\nhave expanded the vocabulary size from 64,000\\nin Baichuan 1 to 125,696, aiming to strike a\\nbalance between computational efficiency and\\nmodel performance.\\nTokenizer V ocab Size Compression Rate ↓\\nLLaMA 2 32,000 1.037\\nBloom 250,680 0.501\\nChatGLM 2 64,794 0.527\\nBaichuan 1 64,000 0.570\\nBaichuan 2 125,696 0.498', metadata={'page': 2, 'source': 'C:\\\\Users\\\\kalin\\\\AppData\\\\Local\\\\Temp\\\\tmpchwtntxm\\\\tmp.pdf'}), Document(page_content='a high compression rate for efficient inference,\\nand an appropriately sized vocabulary to ensure\\nadequate training of each word embedding. We\\nhave taken both these aspects into account. We\\nhave expanded the vocabulary size from 64,000\\nin Baichuan 1 to 125,696, aiming to strike a\\nbalance between computational efficiency and\\nmodel performance.\\nTokenizer V ocab Size Compression Rate ↓\\nLLaMA 2 32,000 1.037\\nBloom 250,680 0.501\\nChatGLM 2 64,794 0.527\\nBaichuan 1 64,000 0.570\\nBaichuan 2 125,696 0.498', metadata={'page': 2, 'source': 'C:\\\\Users\\\\kalin\\\\AppData\\\\Local\\\\Temp\\\\tmpchwtntxm\\\\tmp.pdf'})]\n"
          ]
        }
      ],
      "source": [
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "通过本地部署的模型进行交互"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "i8TTksfT2K3r",
        "OZN6yzwi7J61",
        "lgABYtKp8_Ke",
        "ymUjel7-E-t1"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e42f4231586464abadc5674077b5b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_881fd88d52904346a58d3ed6b7b25b42",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d32c664e3a94141a49200a3bf815719",
            "value": 5
          }
        },
        "17569993d70142caaca7d550eaf84773": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "462fdec12c174c7f893296108744867b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d32c664e3a94141a49200a3bf815719": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a2bda030860431a9ff1bc8719f15d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17569993d70142caaca7d550eaf84773",
            "placeholder": "​",
            "style": "IPY_MODEL_c972648b06754d43ada362e512fea865",
            "value": " 5/7 [00:49&lt;00:20, 10.03s/it]"
          }
        },
        "7f7bd9c4ac8441ad9d252869f75b17e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_853287ee89244e169ffebbd4a7a0335d",
            "placeholder": "​",
            "style": "IPY_MODEL_462fdec12c174c7f893296108744867b",
            "value": "Loading checkpoint shards:  71%"
          }
        },
        "853287ee89244e169ffebbd4a7a0335d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "881fd88d52904346a58d3ed6b7b25b42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c972648b06754d43ada362e512fea865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0c0568f4d6f4bda9253932577becf3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f7bd9c4ac8441ad9d252869f75b17e6",
              "IPY_MODEL_0e42f4231586464abadc5674077b5b85",
              "IPY_MODEL_7a2bda030860431a9ff1bc8719f15d9c"
            ],
            "layout": "IPY_MODEL_d80d0f6e4afb4e709e6a01e3d651b7bf"
          }
        },
        "d80d0f6e4afb4e709e6a01e3d651b7bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
