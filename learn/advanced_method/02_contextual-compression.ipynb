{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 进阶RAG检索   Contextual Compression + Filtering  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 前期准备"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "\n",
        "# Load pdf\n",
        "loader = PyPDFLoader(\"..\\\\..\\\\baichuan.pdf\")\n",
        "data = loader.load()\n",
        "\n",
        "# Split\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "splits = text_splitter.split_documents(data[:6])\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass()\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "# VectorDB\n",
        "embedding = OpenAIEmbeddings(base_url=\"...\")\n",
        "vectordb = Chroma.from_documents(documents=splits, embedding=embedding)\n",
        "\n",
        "retriever = vectordb.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\kalin\\AppData\\Local\\Temp\\ipykernel_10256\\1791937861.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  base_docs = retriever.get_relevant_documents(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'author': '', 'creationdate': '2025-04-18T00:32:55+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-04-18T00:32:55+00:00', 'page': 1, 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\baichuan.pdf', 'subject': '', 'title': '', 'total_pages': 28, 'trapped': '/False'}, page_content='evaluations, Baichuan 2 nearly doubles the results\\nof the Baichuan 1. In addition, Baichuan 2 also\\ndemonstrates strong performance on medical and\\nlegal domain tasks. On benchmarks such as\\nMedQA (Jin et al., 2021) and JEC-QA (Zhong\\net al., 2020), Baichuan 2 outperforms other open-\\nsource models, making it a suitable foundation\\nmodel for domain-specific optimization.\\nAdditionally, we also released two chat\\nmodels, Baichuan 2-7B-Chat and Baichuan 2-'),\n",
              " Document(metadata={'author': '', 'creationdate': '2025-04-18T00:32:55+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-04-18T00:32:55+00:00', 'page': 1, 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\baichuan.pdf', 'subject': '', 'title': '', 'total_pages': 28, 'trapped': '/False'}, page_content='With such a massive amount of training data,\\nBaichuan 2 achieves significant improvements over\\nBaichuan 1. On general benchmarks like MMLU\\n(Hendrycks et al., 2021a), CMMLU (Li et al.,\\n2023), and C-Eval (Huang et al., 2023), Baichuan\\n2-7B achieves nearly 30% higher performance\\ncompared to Baichuan 1-7B. Specifically, Baichuan\\n2 is optimized to improve performance on math\\nand code problems. On the GSM8K (Cobbe\\net al., 2021) and HumanEval (Chen et al., 2021)'),\n",
              " Document(metadata={'author': '', 'creationdate': '2025-04-18T00:32:55+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-04-18T00:32:55+00:00', 'page': 2, 'page_label': '3', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\baichuan.pdf', 'subject': '', 'title': '', 'total_pages': 28, 'trapped': '/False'}, page_content='Baichuan 1-13B-Base 52.40 51.60 55.30 49.69 43.20 43.01 26.76 11.59\\n13B\\nBaichuan 2-13B-Base 58.10 59.17 61.97 54.33 48.17 48.78 52.77 17.07\\nTable 1: Overall results of Baichuan 2 compared with other similarly sized LLMs on general benchmarks. * denotes\\nresults derived from official websites.\\nsystem. The composition of the training corpus is\\nshown in Figure 1.\\nFigure 1: The distribution of different categories of\\nBaichuan 2 training data.\\nData processing: For data processing, we focus'),\n",
              " Document(metadata={'author': '', 'creationdate': '2025-04-18T00:32:55+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-04-18T00:32:55+00:00', 'page': 1, 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\baichuan.pdf', 'subject': '', 'title': '', 'total_pages': 28, 'trapped': '/False'}, page_content='13B-Chat, optimized to follow human instructions.\\nThese models excel at dialogue and context\\nunderstanding. We will elaborate on our\\napproaches to improve the safety of Baichuan 2.\\nBy open-sourcing these models, we hope to enable\\nthe community to further improve the safety of\\nlarge language models, facilitating more research\\non responsible LLMs development.\\nFurthermore, in spirit of research collaboration\\n1https://commoncrawl.org/\\nand continuous improvement, we are also releasing')]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_docs = retriever.get_relevant_documents(\n",
        "    \"What is baichuan2 ？\"\n",
        ")\n",
        "\n",
        "base_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Contextual Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, base_url=\"...\")\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever\n",
        ")\n",
        "\n",
        "compressed_docs = compression_retriever.get_relevant_documents(\n",
        "    \"What is baichuan2 ？\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'author': '', 'creationdate': '2025-04-18T00:32:55+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-04-18T00:32:55+00:00', 'page': 1, 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\baichuan.pdf', 'subject': '', 'title': '', 'total_pages': 28, 'trapped': '/False'}, page_content='Baichuan 2 nearly doubles the results\\nof the Baichuan 1. In addition, Baichuan 2 also\\ndemonstrates strong performance on medical and\\nlegal domain tasks. On benchmarks such as\\nMedQA (Jin et al., 2021) and JEC-QA (Zhong\\net al., 2020), Baichuan 2 outperforms other open-\\nsource models, making it a suitable foundation\\nmodel for domain-specific optimization.'),\n",
              " Document(metadata={'author': '', 'creationdate': '2025-04-18T00:32:55+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-04-18T00:32:55+00:00', 'page': 1, 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\baichuan.pdf', 'subject': '', 'title': '', 'total_pages': 28, 'trapped': '/False'}, page_content='Baichuan 2 achieves significant improvements over Baichuan 1. Specifically, Baichuan 2 is optimized to improve performance on math and code problems.'),\n",
              " Document(metadata={'author': '', 'creationdate': '2025-04-18T00:32:55+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-04-18T00:32:55+00:00', 'page': 2, 'page_label': '3', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\baichuan.pdf', 'subject': '', 'title': '', 'total_pages': 28, 'trapped': '/False'}, page_content='Baichuan 2-13B-Base 58.10 59.17 61.97 54.33 48.17 48.78 52.77 17.07'),\n",
              " Document(metadata={'author': '', 'creationdate': '2025-04-18T00:32:55+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-04-18T00:32:55+00:00', 'page': 1, 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\baichuan.pdf', 'subject': '', 'title': '', 'total_pages': 28, 'trapped': '/False'}, page_content='Baichuan 2.')]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compressed_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Contextual filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### LLMChainFilter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'author': '', 'creationdate': '2025-04-18T00:32:55+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-04-18T00:32:55+00:00', 'page': 1, 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\baichuan.pdf', 'subject': '', 'title': '', 'total_pages': 28, 'trapped': '/False'}, page_content='evaluations, Baichuan 2 nearly doubles the results\\nof the Baichuan 1. In addition, Baichuan 2 also\\ndemonstrates strong performance on medical and\\nlegal domain tasks. On benchmarks such as\\nMedQA (Jin et al., 2021) and JEC-QA (Zhong\\net al., 2020), Baichuan 2 outperforms other open-\\nsource models, making it a suitable foundation\\nmodel for domain-specific optimization.\\nAdditionally, we also released two chat\\nmodels, Baichuan 2-7B-Chat and Baichuan 2-'),\n",
              " Document(metadata={'author': '', 'creationdate': '2025-04-18T00:32:55+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-04-18T00:32:55+00:00', 'page': 1, 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\baichuan.pdf', 'subject': '', 'title': '', 'total_pages': 28, 'trapped': '/False'}, page_content='With such a massive amount of training data,\\nBaichuan 2 achieves significant improvements over\\nBaichuan 1. On general benchmarks like MMLU\\n(Hendrycks et al., 2021a), CMMLU (Li et al.,\\n2023), and C-Eval (Huang et al., 2023), Baichuan\\n2-7B achieves nearly 30% higher performance\\ncompared to Baichuan 1-7B. Specifically, Baichuan\\n2 is optimized to improve performance on math\\nand code problems. On the GSM8K (Cobbe\\net al., 2021) and HumanEval (Chen et al., 2021)'),\n",
              " Document(metadata={'author': '', 'creationdate': '2025-04-18T00:32:55+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-04-18T00:32:55+00:00', 'page': 2, 'page_label': '3', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\baichuan.pdf', 'subject': '', 'title': '', 'total_pages': 28, 'trapped': '/False'}, page_content='Baichuan 1-13B-Base 52.40 51.60 55.30 49.69 43.20 43.01 26.76 11.59\\n13B\\nBaichuan 2-13B-Base 58.10 59.17 61.97 54.33 48.17 48.78 52.77 17.07\\nTable 1: Overall results of Baichuan 2 compared with other similarly sized LLMs on general benchmarks. * denotes\\nresults derived from official websites.\\nsystem. The composition of the training corpus is\\nshown in Figure 1.\\nFigure 1: The distribution of different categories of\\nBaichuan 2 training data.\\nData processing: For data processing, we focus'),\n",
              " Document(metadata={'author': '', 'creationdate': '2025-04-18T00:32:55+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-04-18T00:32:55+00:00', 'page': 1, 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\baichuan.pdf', 'subject': '', 'title': '', 'total_pages': 28, 'trapped': '/False'}, page_content='13B-Chat, optimized to follow human instructions.\\nThese models excel at dialogue and context\\nunderstanding. We will elaborate on our\\napproaches to improve the safety of Baichuan 2.\\nBy open-sourcing these models, we hope to enable\\nthe community to further improve the safety of\\nlarge language models, facilitating more research\\non responsible LLMs development.\\nFurthermore, in spirit of research collaboration\\n1https://commoncrawl.org/\\nand continuous improvement, we are also releasing')]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.retrievers.document_compressors import LLMChainFilter\n",
        "\n",
        "_filter = LLMChainFilter.from_llm(llm)\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=_filter, base_retriever=retriever\n",
        ")\n",
        "\n",
        "compressed_docs = compression_retriever.get_relevant_documents(\n",
        "    \"What is baichuan2 ？\"\n",
        ")\n",
        "\n",
        "compressed_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### EmbeddingsFilter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
        "\n",
        "embeddings_filter = EmbeddingsFilter(embeddings=embedding, similarity_threshold=0.76)\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=embeddings_filter, base_retriever=retriever\n",
        ")\n",
        "\n",
        "compressed_docs = compression_retriever.get_relevant_documents(\n",
        "    \"What is baichuan2 ？\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compressed_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
